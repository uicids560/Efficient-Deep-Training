{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/uicids560/Efficient-Deep-Training/blob/main/Cifar100_GoogLeNet_GradMatch_Epoch_%3D_20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GoogLeNet - GradMatch - CIFAR100\n",
        "GoogLeNet Model Architecture and GradMatch Strategy from CORDS: https://github.com/decile-team/cords/blob/844f897ea4ed7e2f9c1453888022c281bb2091be/examples/SL/image_classification/python_notebooks/CORDS_SL_CIFAR10_Custom_Train.ipynb"
      ],
      "metadata": {
        "id": "p5RTeEEocPnE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cloning CORDS repository & Install prerequisite libraries of CORDS"
      ],
      "metadata": {
        "id": "plXHZIDJg5yE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dB19yvphJVL",
        "outputId": "e8093e2a-27a8-4835-cc50-41ab347b35a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'cords' already exists and is not an empty directory.\n",
            "/content/cords\n",
            "\u001b[0m\u001b[01;34mbenchmarks\u001b[0m/   \u001b[01;34mcords\u001b[0m/  \u001b[01;34mexamples\u001b[0m/    \u001b[01;34mrequirements\u001b[0m/  \u001b[01;34mtests\u001b[0m/        train_ssl.py\n",
            "CITATION.CFF  \u001b[01;34mdata\u001b[0m/   LICENSE.txt  \u001b[01;34mresults\u001b[0m/       train_hpo.py\n",
            "\u001b[01;34mconfigs\u001b[0m/      \u001b[01;34mdocs\u001b[0m/   README.md    setup.py       train_sl.py\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: dotmap in /usr/local/lib/python3.7/dist-packages (1.3.30)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: apricot-select in /usr/local/lib/python3.7/dist-packages (0.6.1)\n",
            "Requirement already satisfied: numpy>=1.14.2 in /usr/local/lib/python3.7/dist-packages (from apricot-select) (1.21.6)\n",
            "Requirement already satisfied: tqdm>=4.24.0 in /usr/local/lib/python3.7/dist-packages (from apricot-select) (4.64.1)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from apricot-select) (0.56.4)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from apricot-select) (1.7.3)\n",
            "Requirement already satisfied: nose in /usr/local/lib/python3.7/dist-packages (from apricot-select) (1.3.7)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->apricot-select) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->apricot-select) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->apricot-select) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->numba>=0.43.0->apricot-select) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->numba>=0.43.0->apricot-select) (4.1.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ray[default] in /usr/local/lib/python3.7/dist-packages (2.1.0)\n",
            "Requirement already satisfied: grpcio>=1.32.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]) (1.50.0)\n",
            "Requirement already satisfied: click<=8.0.4,>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]) (7.1.2)\n",
            "Requirement already satisfied: virtualenv>=20.0.24 in /usr/local/lib/python3.7/dist-packages (from ray[default]) (20.16.7)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.7/dist-packages (from ray[default]) (1.3.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ray[default]) (2.23.0)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.7/dist-packages (from ray[default]) (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from ray[default]) (1.21.6)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[default]) (4.3.3)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray[default]) (3.19.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray[default]) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from ray[default]) (4.1.1)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from ray[default]) (22.1.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]) (1.0.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray[default]) (6.0)\n",
            "Requirement already satisfied: py-spy>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]) (0.3.14)\n",
            "Requirement already satisfied: prometheus-client<0.14.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from ray[default]) (0.13.1)\n",
            "Requirement already satisfied: gpustat>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]) (1.0.0)\n",
            "Requirement already satisfied: aiohttp-cors in /usr/local/lib/python3.7/dist-packages (from ray[default]) (0.7.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.7/dist-packages (from ray[default]) (1.10.2)\n",
            "Requirement already satisfied: aiohttp>=3.7 in /usr/local/lib/python3.7/dist-packages (from ray[default]) (3.8.3)\n",
            "Requirement already satisfied: smart-open in /usr/local/lib/python3.7/dist-packages (from ray[default]) (5.2.1)\n",
            "Requirement already satisfied: opencensus in /usr/local/lib/python3.7/dist-packages (from ray[default]) (0.11.0)\n",
            "Requirement already satisfied: colorful in /usr/local/lib/python3.7/dist-packages (from ray[default]) (0.5.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.7->ray[default]) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.7->ray[default]) (1.8.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.7->ray[default]) (6.0.2)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.7->ray[default]) (0.13.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.7->ray[default]) (2.1.1)\n",
            "Requirement already satisfied: psutil>=5.6.0 in /usr/local/lib/python3.7/dist-packages (from gpustat>=1.0.0->ray[default]) (5.9.4)\n",
            "Requirement already satisfied: blessed>=1.17.1 in /usr/local/lib/python3.7/dist-packages (from gpustat>=1.0.0->ray[default]) (1.19.1)\n",
            "Requirement already satisfied: six>=1.7 in /usr/local/lib/python3.7/dist-packages (from gpustat>=1.0.0->ray[default]) (1.15.0)\n",
            "Requirement already satisfied: nvidia-ml-py<=11.495.46,>=11.450.129 in /usr/local/lib/python3.7/dist-packages (from gpustat>=1.0.0->ray[default]) (11.495.46)\n",
            "Requirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.7/dist-packages (from blessed>=1.17.1->gpustat>=1.0.0->ray[default]) (0.2.5)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.3 in /usr/local/lib/python3.7/dist-packages (from virtualenv>=20.0.24->ray[default]) (4.13.0)\n",
            "Requirement already satisfied: distlib<1,>=0.3.6 in /usr/local/lib/python3.7/dist-packages (from virtualenv>=20.0.24->ray[default]) (0.3.6)\n",
            "Requirement already satisfied: platformdirs<3,>=2.4 in /usr/local/lib/python3.7/dist-packages (from virtualenv>=20.0.24->ray[default]) (2.5.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.3->virtualenv>=20.0.24->ray[default]) (3.10.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl<2.0,>=1.0->aiohttp>=3.7->ray[default]) (2.10)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[default]) (5.10.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[default]) (0.19.2)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray[default]) (2.8.2)\n",
            "Requirement already satisfied: opencensus-context>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray[default]) (0.1.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]) (1.56.4)\n",
            "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]) (2.14.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]) (5.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]) (0.2.8)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray[default]) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray[default]) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->ray[default]) (3.0.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ray[tune] in /usr/local/lib/python3.7/dist-packages (2.1.0)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.3.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (3.8.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (4.3.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (4.1.1)\n",
            "Requirement already satisfied: grpcio>=1.32.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.50.0)\n",
            "Requirement already satisfied: click<=8.0.4,>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (7.1.2)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (22.1.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.0.4)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (2.23.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (6.0)\n",
            "Requirement already satisfied: virtualenv>=20.0.24 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (20.16.7)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (3.19.6)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.3.1)\n",
            "Requirement already satisfied: tensorboardX>=1.9 in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (2.5.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (1.3.5)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from ray[tune]) (0.8.10)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio>=1.32.0->ray[tune]) (1.15.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.3 in /usr/local/lib/python3.7/dist-packages (from virtualenv>=20.0.24->ray[tune]) (4.13.0)\n",
            "Requirement already satisfied: platformdirs<3,>=2.4 in /usr/local/lib/python3.7/dist-packages (from virtualenv>=20.0.24->ray[tune]) (2.5.4)\n",
            "Requirement already satisfied: distlib<1,>=0.3.6 in /usr/local/lib/python3.7/dist-packages (from virtualenv>=20.0.24->ray[tune]) (0.3.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.3->virtualenv>=20.0.24->ray[tune]) (3.10.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[tune]) (5.10.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[tune]) (0.19.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ray[tune]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->ray[tune]) (2022.6)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ray[tune]) (2.10)\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/decile-team/cords.git\n",
        "%cd cords/\n",
        "%ls\n",
        "\n",
        "!pip install dotmap\n",
        "!pip install apricot-select\n",
        "!pip install ray[default]\n",
        "!pip install ray[tune]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Import necessary libraries"
      ],
      "metadata": {
        "id": "FAe7hUD2g-_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from cords.utils.data.datasets.SL import gen_dataset\n",
        "from torch.utils.data import Subset\n",
        "from cords.utils.config_utils import load_config_data\n",
        "import os.path as osp\n",
        "from cords.utils.data.data_utils import WeightedSubset\n",
        "from ray import tune"
      ],
      "metadata": {
        "id": "ksBX97-0hQA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Loading the CIFAR100 dataset & Create dataloaders"
      ],
      "metadata": {
        "id": "BBn3mltHhRKF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainset, validset, testset, num_cls = gen_dataset('data/', 'cifar100', None, isnumpy=False)\n",
        "trn_batch_size = 20\n",
        "val_batch_size = 20\n",
        "tst_batch_size = 1200\n",
        "\n",
        "# Creating the Data Loaders\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=trn_batch_size,\n",
        "                                          shuffle=False, pin_memory=True)\n",
        "\n",
        "valloader = torch.utils.data.DataLoader(validset, batch_size=val_batch_size,\n",
        "                                        shuffle=False, pin_memory=True)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=tst_batch_size,\n",
        "                                          shuffle=False, pin_memory=True)"
      ],
      "metadata": {
        "id": "vhhh5p3ghV1J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4178d2f1-3f00-45fb-f066-bac3d68dbe4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining Model"
      ],
      "metadata": {
        "id": "bPbYKHh6hcEZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from cords.utils.models import GoogLeNet\n",
        "numclasses = 100\n",
        "device = 'cuda' #Device Argument\n",
        "model = GoogLeNet(100)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "Y4CQQDFqhfpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Defining Loss Functions, Cumulative time calculation, Optimizers and schedulers"
      ],
      "metadata": {
        "id": "XPHN3wW_hiIK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "criterion_nored = nn.CrossEntropyLoss(reduction='none')\n",
        "\n",
        "def generate_cumulative_timing(mod_timing):\n",
        "    tmp = 0\n",
        "    mod_cum_timing = np.zeros(len(mod_timing))\n",
        "    for i in range(len(mod_timing)):\n",
        "        tmp += mod_timing[i]\n",
        "        mod_cum_timing[i] = tmp\n",
        "    return mod_cum_timing / 3600\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-2,\n",
        "                                  momentum=0.9,\n",
        "                                  weight_decay=5e-4,\n",
        "                                  nesterov=False)\n",
        "\n",
        "#T_max is the maximum number of scheduler steps. Here we are using the number of epochs as the maximum number of scheduler steps.\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,\n",
        "                                                       T_max=300)"
      ],
      "metadata": {
        "id": "emgtRNEthoS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logger Object for Loggging"
      ],
      "metadata": {
        "id": "zCn_IYG5huub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def __get_logger(results_dir):\n",
        "  os.makedirs(results_dir, exist_ok=True)\n",
        "  # setup logger\n",
        "  plain_formatter = logging.Formatter(\"[%(asctime)s] %(name)s %(levelname)s: %(message)s\",\n",
        "                                      datefmt=\"%m/%d %H:%M:%S\")\n",
        "  logger = logging.getLogger(__name__)\n",
        "  logger.setLevel(logging.INFO)\n",
        "  s_handler = logging.StreamHandler(stream=sys.stdout)\n",
        "  s_handler.setFormatter(plain_formatter)\n",
        "  s_handler.setLevel(logging.INFO)\n",
        "  logger.addHandler(s_handler)\n",
        "  f_handler = logging.FileHandler(os.path.join(results_dir, \"results.log\"))\n",
        "  f_handler.setFormatter(plain_formatter)\n",
        "  f_handler.setLevel(logging.DEBUG)\n",
        "  logger.addHandler(f_handler)\n",
        "  logger.propagate = False\n",
        "  return logger\n",
        "\n",
        "import logging\n",
        "import os\n",
        "import os.path as osp\n",
        "import sys\n",
        "\n",
        "#Results logging directory\n",
        "results_dir = osp.abspath(osp.expanduser('results'))\n",
        "logger = __get_logger(results_dir)"
      ],
      "metadata": {
        "id": "dKtFQvf6hyfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initiating GradMatch subset selection dataloaders\n",
        "\n"
      ],
      "metadata": {
        "id": "-x8m74K0h2xl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from cords.utils.data.dataloader.SL.adaptive import GradMatchDataLoader\n",
        "from dotmap import DotMap\n",
        "\n",
        "selection_strategy = 'GradMatch'\n",
        "dss_args = dict(model=model,\n",
        "                loss=criterion_nored,\n",
        "                eta=0.1,\n",
        "                num_classes=100,\n",
        "                num_epochs=20,\n",
        "                device='cuda',\n",
        "                fraction=0.7,\n",
        "                select_every=20,\n",
        "                kappa=0,\n",
        "                num_samples = 20,\n",
        "                linear_layer=False,\n",
        "                selection_type='PerBatch',\n",
        "                greedy='Stochastic',\n",
        "                optimizer='lazy',\n",
        "                valid=False,\n",
        "                v1=True,\n",
        "                lam=0,\n",
        "                eps=1e-4)\n",
        "\n",
        "\"\"\"\n",
        "  Optimizer: str\n",
        "            The optimization approach for data selection. Must be one of\n",
        "            'random', 'modular', 'naive', 'lazy', 'approximate-lazy', 'two-stage',\n",
        "            'stochastic', 'sample', 'greedi', 'bidirectional'\n",
        "  Type of greedy selection algorithm:\n",
        "        - 'RGreedy' : RGreedy Selection method is a variant of naive greedy where we just perform r rounds of greedy selection by choosing k/r points in each round.\n",
        "        - 'Stochastic' : Stochastic greedy selection method is based on the algorithm presented in this paper :footcite:`mirzasoleiman2014lazier`\n",
        "        - 'Naive' : Normal naive greedy selection method that selects a single best element every step until the budget is fulfilled\n",
        "  Type of selection \n",
        "        - ‘PerClass’: PerClass method is where OMP algorithm is applied on each class data points seperately. \n",
        "        - ‘PerBatch’: PerBatch method is where OMP algorithm is applied on each minibatch data points. \n",
        "        - ‘PerClassPerGradient’: PerClassPerGradient method is same as PerClass but we use the gradient corresponding to classification layer of that class only.\n",
        "\"\"\"\n",
        "\n",
        "dss_args = DotMap(dss_args)\n",
        "\n",
        "dataloader = GradMatchDataLoader(trainloader, valloader, dss_args, logger, \n",
        "                                  batch_size=20,\n",
        "                                  shuffle=False,\n",
        "                                  pin_memory=False)"
      ],
      "metadata": {
        "id": "hK-voguUh8Dl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Arguments for training and evaluation"
      ],
      "metadata": {
        "id": "xYD-bMueh_c9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Training Arguments\n",
        "num_epochs = 20\n",
        "\n",
        "#Arguments for results logging\n",
        "print_every = 1\n",
        "print_args = [\"val_loss\", \"val_acc\", \"tst_loss\", \"tst_acc\", \"time\"]\n",
        "\n",
        "#Evaluation Metrics\n",
        "trn_losses = list()\n",
        "val_losses = list()\n",
        "tst_losses = list()\n",
        "subtrn_losses = list()\n",
        "timing = list()\n",
        "trn_acc = list()\n",
        "val_acc = list()  \n",
        "tst_acc = list()  \n",
        "subtrn_acc = list()"
      ],
      "metadata": {
        "id": "hZSdpIhYiBDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training loop with evaluation"
      ],
      "metadata": {
        "id": "n343vNkLiHtM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Training Loop\n",
        "for epoch in range(num_epochs):\n",
        "    subtrn_loss = 0\n",
        "    subtrn_correct = 0\n",
        "    subtrn_total = 0\n",
        "    model.train()\n",
        "    start_time = time.time()\n",
        "    for _, (inputs, targets, weights) in enumerate(dataloader):\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device, non_blocking=True)\n",
        "        weights = weights.to(device)  \n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        losses = criterion_nored(outputs, targets)\n",
        "        loss = torch.dot(losses, weights/(weights.sum()))\n",
        "        loss.backward()\n",
        "        subtrn_loss += loss.item()\n",
        "        optimizer.step()\n",
        "        _, predicted = outputs.max(1)\n",
        "        subtrn_total += targets.size(0)\n",
        "        subtrn_correct += predicted.eq(targets).sum().item()\n",
        "    epoch_time = time.time() - start_time\n",
        "    scheduler.step()\n",
        "    timing.append(epoch_time)\n",
        "\n",
        "    #Evaluation Loop\n",
        "    if (epoch + 1) % print_every == 0:\n",
        "        trn_loss = 0\n",
        "        trn_correct = 0\n",
        "        trn_total = 0\n",
        "        val_loss = 0\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "        tst_correct = 0\n",
        "        tst_total = 0\n",
        "        tst_loss = 0\n",
        "        model.eval()\n",
        "\n",
        "        if (\"trn_loss\" in print_args) or (\"trn_acc\" in print_args):\n",
        "            with torch.no_grad():\n",
        "                for _, (inputs, targets) in enumerate(trainloader):\n",
        "                    inputs, targets = inputs.to(device), \\\n",
        "                                      targets.to(device, non_blocking=True)\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, targets)\n",
        "                    trn_loss += loss.item()\n",
        "                    if \"trn_acc\" in print_args:\n",
        "                        _, predicted = outputs.max(1)\n",
        "                        trn_total += targets.size(0)\n",
        "                        trn_correct += predicted.eq(targets).sum().item()\n",
        "                trn_losses.append(trn_loss)\n",
        "\n",
        "            if \"trn_acc\" in print_args:\n",
        "                trn_acc.append(trn_correct / trn_total)\n",
        "\n",
        "        if (\"val_loss\" in print_args) or (\"val_acc\" in print_args):\n",
        "            with torch.no_grad():\n",
        "                for _, (inputs, targets) in enumerate(valloader):\n",
        "                    inputs, targets = inputs.to(device), \\\n",
        "                                      targets.to(device, non_blocking=True)\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, targets)\n",
        "                    val_loss += loss.item()\n",
        "                    if \"val_acc\" in print_args:\n",
        "                        _, predicted = outputs.max(1)\n",
        "                        val_total += targets.size(0)\n",
        "                        val_correct += predicted.eq(targets).sum().item()\n",
        "                val_losses.append(val_loss)\n",
        "\n",
        "            if \"val_acc\" in print_args:\n",
        "                val_acc.append(val_correct / val_total)\n",
        "\n",
        "        if (\"tst_loss\" in print_args) or (\"tst_acc\" in print_args):\n",
        "            with torch.no_grad():\n",
        "                for _, (inputs, targets) in enumerate(testloader):\n",
        "                    inputs, targets = inputs.to(device), \\\n",
        "                                      targets.to(device, non_blocking=True)\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, targets)\n",
        "                    tst_loss += loss.item()\n",
        "                    if \"tst_acc\" in print_args:\n",
        "                        _, predicted = outputs.max(1)\n",
        "                        tst_total += targets.size(0)\n",
        "                        tst_correct += predicted.eq(targets).sum().item()\n",
        "                tst_losses.append(tst_loss)\n",
        "\n",
        "            if \"tst_acc\" in print_args:\n",
        "                tst_acc.append(tst_correct / tst_total)\n",
        "\n",
        "        if \"subtrn_acc\" in print_args:\n",
        "            subtrn_acc.append(subtrn_correct / subtrn_total)\n",
        "\n",
        "        if \"subtrn_losses\" in print_args:\n",
        "            subtrn_losses.append(subtrn_loss)\n",
        "\n",
        "        print_str = \"Epoch: \" + str(epoch + 1)\n",
        "\n",
        "        #Results Printing\n",
        "        for arg in print_args:\n",
        "\n",
        "            if arg == \"val_loss\":\n",
        "                print_str += \" , \" + \"Validation Loss: \" + str(val_losses[-1])\n",
        "\n",
        "            if arg == \"val_acc\":\n",
        "                print_str += \" , \" + \"Validation Accuracy: \" + str(val_acc[-1])\n",
        "\n",
        "            if arg == \"tst_loss\":\n",
        "                print_str += \" , \" + \"Test Loss: \" + str(tst_losses[-1])\n",
        "\n",
        "            if arg == \"tst_acc\":\n",
        "                print_str += \" , \" + \"Test Accuracy: \" + str(tst_acc[-1])\n",
        "\n",
        "            if arg == \"trn_loss\":\n",
        "                print_str += \" , \" + \"Training Loss: \" + str(trn_losses[-1])\n",
        "\n",
        "            if arg == \"trn_acc\":\n",
        "                print_str += \" , \" + \"Training Accuracy: \" + str(trn_acc[-1])\n",
        "\n",
        "            if arg == \"subtrn_loss\":\n",
        "                print_str += \" , \" + \"Subset Loss: \" + str(subtrn_losses[-1])\n",
        "\n",
        "            if arg == \"subtrn_acc\":\n",
        "                print_str += \" , \" + \"Subset Accuracy: \" + str(subtrn_acc[-1])\n",
        "\n",
        "            if arg == \"time\":\n",
        "                print_str += \" , \" + \"Timing: \" + str(timing[-1])\n",
        "\n",
        "        logger.info(print_str)"
      ],
      "metadata": {
        "id": "TV_yLtEFiH_k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5f66e74-6bab-484b-ecc6-79cf73e0dbb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[11/17 02:55:26] __main__ INFO: Epoch: 1 , Validation Loss: 870.9864399433136 , Validation Accuracy: 0.151 , Test Loss: 31.231834888458252 , Test Accuracy: 0.1533 , Timing: 93.1084291934967\n",
            "[11/17 02:57:04] __main__ INFO: Epoch: 2 , Validation Loss: 714.3213121891022 , Validation Accuracy: 0.2718 , Test Loss: 26.372188806533813 , Test Accuracy: 0.2607 , Timing: 89.81882381439209\n",
            "[11/17 02:58:43] __main__ INFO: Epoch: 3 , Validation Loss: 652.3813457489014 , Validation Accuracy: 0.3184 , Test Loss: 23.21185541152954 , Test Accuracy: 0.3336 , Timing: 90.47791624069214\n",
            "[11/17 03:00:22] __main__ INFO: Epoch: 4 , Validation Loss: 560.7317037582397 , Validation Accuracy: 0.3914 , Test Loss: 20.29040265083313 , Test Accuracy: 0.3962 , Timing: 90.3605649471283\n",
            "[11/17 03:02:02] __main__ INFO: Epoch: 5 , Validation Loss: 513.9242636561394 , Validation Accuracy: 0.4412 , Test Loss: 18.507211923599243 , Test Accuracy: 0.4453 , Timing: 90.8587293624878\n",
            "[11/17 03:03:42] __main__ INFO: Epoch: 6 , Validation Loss: 478.0746866464615 , Validation Accuracy: 0.4774 , Test Loss: 16.869100332260132 , Test Accuracy: 0.4878 , Timing: 91.39548587799072\n",
            "[11/17 03:05:22] __main__ INFO: Epoch: 7 , Validation Loss: 458.9722663164139 , Validation Accuracy: 0.4968 , Test Loss: 16.55668532848358 , Test Accuracy: 0.4997 , Timing: 91.48524570465088\n",
            "[11/17 03:07:02] __main__ INFO: Epoch: 8 , Validation Loss: 434.6699473261833 , Validation Accuracy: 0.5212 , Test Loss: 15.66288435459137 , Test Accuracy: 0.5244 , Timing: 90.697505235672\n",
            "[11/17 03:08:41] __main__ INFO: Epoch: 9 , Validation Loss: 423.61543291807175 , Validation Accuracy: 0.5358 , Test Loss: 15.14598286151886 , Test Accuracy: 0.544 , Timing: 91.27124047279358\n",
            "[11/17 03:10:22] __main__ INFO: Epoch: 10 , Validation Loss: 414.13815718889236 , Validation Accuracy: 0.5488 , Test Loss: 15.057826519012451 , Test Accuracy: 0.548 , Timing: 91.25142669677734\n",
            "[11/17 03:12:02] __main__ INFO: Epoch: 11 , Validation Loss: 399.7923461198807 , Validation Accuracy: 0.564 , Test Loss: 14.376731276512146 , Test Accuracy: 0.5698 , Timing: 91.43094825744629\n",
            "[11/17 03:13:41] __main__ INFO: Epoch: 12 , Validation Loss: 397.2974588871002 , Validation Accuracy: 0.5578 , Test Loss: 14.095646023750305 , Test Accuracy: 0.577 , Timing: 91.15507006645203\n",
            "[11/17 03:15:21] __main__ INFO: Epoch: 13 , Validation Loss: 415.61653929948807 , Validation Accuracy: 0.5578 , Test Loss: 15.177996635437012 , Test Accuracy: 0.5589 , Timing: 91.17583227157593\n",
            "[11/17 03:17:00] __main__ INFO: Epoch: 14 , Validation Loss: 413.65961587429047 , Validation Accuracy: 0.5622 , Test Loss: 15.082120418548584 , Test Accuracy: 0.5703 , Timing: 90.56691527366638\n",
            "[11/17 03:18:39] __main__ INFO: Epoch: 15 , Validation Loss: 409.8620295226574 , Validation Accuracy: 0.5688 , Test Loss: 15.010267734527588 , Test Accuracy: 0.5733 , Timing: 90.01866793632507\n",
            "[11/17 03:20:18] __main__ INFO: Epoch: 16 , Validation Loss: 408.9408333301544 , Validation Accuracy: 0.577 , Test Loss: 14.880697250366211 , Test Accuracy: 0.5871 , Timing: 91.39841771125793\n",
            "[11/17 03:21:58] __main__ INFO: Epoch: 17 , Validation Loss: 426.7672135233879 , Validation Accuracy: 0.5642 , Test Loss: 15.829900741577148 , Test Accuracy: 0.568 , Timing: 91.05681014060974\n",
            "[11/17 03:23:37] __main__ INFO: Epoch: 18 , Validation Loss: 436.25395664572716 , Validation Accuracy: 0.5536 , Test Loss: 16.18553340435028 , Test Accuracy: 0.567 , Timing: 90.37732863426208\n",
            "[11/17 03:25:16] __main__ INFO: Epoch: 19 , Validation Loss: 414.61574697494507 , Validation Accuracy: 0.5682 , Test Loss: 15.573938131332397 , Test Accuracy: 0.5816 , Timing: 90.50926899909973\n",
            "[11/17 03:26:55] __main__ INFO: Epoch: 20 , Validation Loss: 422.1172294616699 , Validation Accuracy: 0.5772 , Test Loss: 16.19915246963501 , Test Accuracy: 0.581 , Timing: 90.34485125541687\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Results Summary"
      ],
      "metadata": {
        "id": "UtVZ8GaXiNSe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"CORDS Selection Method: {0:s}\".format(selection_strategy))\n",
        "print(\"Final SubsetTrn: {0:f}\".format(subtrn_loss))\n",
        "if \"val_loss\" in print_args:\n",
        "    if \"val_acc\" in print_args:\n",
        "        print(\"Validation Loss:\", val_loss, \"/ Validation Accuracy:\", val_acc[-1])\n",
        "    else:\n",
        "        print(\"Validation Loss:\", val_loss)\n",
        "\n",
        "if \"tst_loss\" in print_args:\n",
        "    if \"tst_acc\" in print_args:\n",
        "        print(\"Test Loss:\", tst_loss, \"/ Test Accuracy:\", tst_acc[-1])\n",
        "    else:\n",
        "        print(\"Test Data Loss:\", tst_loss)\n",
        "\n",
        "if \"time\" in print_args:\n",
        "    time_str = \"Time, \"\n",
        "    for t in timing:\n",
        "        time_str = time_str + \" , \" + str(t)\n",
        "\n",
        "timing_array = np.array(timing)\n",
        "cum_timing = list(generate_cumulative_timing(timing_array))\n",
        "print(\"Total time taken by\", selection_strategy, \"=\", cum_timing[-1])"
      ],
      "metadata": {
        "id": "jdNe2d33iOeK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3796332a-56b2-48e9-b307-db7e2eb611f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CORDS Selection Method: GradMatch\n",
            "Final SubsetTrn: 1137.302998\n",
            "Validation Loss: 422.1172294616699 / Validation Accuracy: 0.5772\n",
            "Test Loss: 16.19915246963501 / Test Accuracy: 0.581\n",
            "Total time taken by GradMatch = 0.5052109661367205\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
